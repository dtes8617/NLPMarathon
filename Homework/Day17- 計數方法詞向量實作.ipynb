{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解如何使用計數方法詞向量與SVD\n",
    "\n",
    "再將文字資料輸入模型進行自然語言任務之前，其中一項重要的前處理即為將字詞向量化(詞嵌入word embedding)。 而將詞向量化的方法有很多，這裡我們會著重在介紹如何使用計數方法來將字詞向量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字詞前處理\n",
    "\n",
    "在進行字詞向量化之前，我們需要針對文本資料進行前置處理，將**文本資料分割成字詞(斷詞)**，再將分割後的**字詞轉換成字詞ID清單**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed corpus: [[0 1 5 6 4 1 3 2]] \n",
      " word2idx: {'you': 0, 'say': 1, '.': 2, 'hello': 3, 'i': 4, 'goodbye': 5, 'and': 6} \n",
      " idx2word: {0: 'you', 1: 'say', 2: '.', 3: 'hello', 4: 'i', 5: 'goodbye', 6: 'and'}\n"
     ]
    }
   ],
   "source": [
    "#導入會使用的library\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "#定義前處理函式\n",
    "def preprocess(corpus: List[str], only_word: bool = False):\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    '''\n",
    "    word_dic = set()\n",
    "    processed_sentence = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        #將所有字詞轉為小寫\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        #移除標點符號(可以依據使用狀況決定是否要移除標點符號)\n",
    "        if only_word:\n",
    "            pattern = r'[^\\W_]+'\n",
    "            sentence = re.findall(pattern, sentence)\n",
    "        else:\n",
    "            punctuation_list = ['.', ',', '!', '?']\n",
    "            for pun in punctuation_list:\n",
    "                sentence = sentence.replace(pun, ' '+pun)\n",
    "            sentence = sentence.split(' ')\n",
    "        \n",
    "        #添加字詞到字典中\n",
    "        word_dic |= set(sentence)\n",
    "        processed_sentence.append(sentence)\n",
    "    \n",
    "    \n",
    "    #建立字詞ID清單\n",
    "    word2idx = dict()\n",
    "    idx2word = dict()\n",
    "    for word in word_dic:\n",
    "        if word not in word2idx:\n",
    "            idx = len(word2idx)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "\n",
    "    #將文本轉為ID型式\n",
    "    id_mapping = lambda x: word2idx[x]\n",
    "    \n",
    "    corpus = np.array([list(map(id_mapping, sentence)) for sentence in processed_sentence])\n",
    "\n",
    "    return corpus, word2idx, idx2word\n",
    "\n",
    "#定義簡易文本資料(使用Ch17講義中的例子)\n",
    "corpus = ['You say goodbye and I say hello.']\n",
    "\n",
    "processed_corpus, word2idx, idx2word = preprocess(corpus)\n",
    "print(f'Processed corpus: {processed_corpus} \\n word2idx: {word2idx} \\n idx2word: {idx2word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共現矩陣\n",
    "將轉化處理過的文本資料轉化為共現矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 2],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義共現矩陣函式\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            for i in range(1, window_size+1):\n",
    "                left_idx = idx - i\n",
    "                right_idx = idx + i\n",
    "\n",
    "                if left_idx >= 0:\n",
    "                    left_word_id = sentence[left_idx]\n",
    "                    co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "                if right_idx < sentence_size:\n",
    "                    right_word_id = sentence[right_idx]\n",
    "                    co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 2],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義共現矩陣函式\n",
    "# method two\n",
    "\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            left_idx = idx - window_size if idx - window_size >= 0 else 0\n",
    "            context_ids = sentence[left_idx:idx]\n",
    "            \n",
    "            for left_i, left_id in enumerate(context_ids):\n",
    "                co_matrix[word_id, left_id] += 1\n",
    "                co_matrix[left_id, word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量間相似度\n",
    "比較轉換為向量的字詞的方法有很多種，其中當要表示字詞的相似度時，最常使用的方法為餘弦相似度 (Cosine Similarity)\n",
    "\n",
    "$$\n",
    "sim(x,y) = \\frac{xy}{||x||||y||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067726510136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義餘弦相似度\n",
    "def cos_similarity(x: np.ndarray, y: np.ndarray, eps: float=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    \n",
    "    return np.dot(nx,ny)\n",
    "\n",
    "# calculate the similarity between I and you\n",
    "cos_similarity(co_matrix[word2idx['i']], co_matrix[word2idx['you']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立可供查詢相似度的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入字詞，查詢與此字詞top_n相似的結果\n",
    "def top_k_similarity(query: str, word2idx: dict, idx2word: dict, word_matrix: np.ndarray, top_k: int=3):\n",
    "    # handle the situation of query word not in corpus\n",
    "    if query not in word2idx:\n",
    "        raise ValueError(f\"{query} is not found in input dictionary\")\n",
    "    \n",
    "    # handle the situation of top_k is the same as the amount of words\n",
    "    if top_k >= len(word2idx):\n",
    "        raise ValueError(f\"top_k needs to be less than the amount of words\")\n",
    "        \n",
    "    print(f\"[query] : {query}\")\n",
    "    query_id = word2idx[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    similarity_scores = np.zeros(len(word2idx))\n",
    "    for i in range(len(word2idx)):\n",
    "        similarity_scores[i] = cos_similarity(query_vec, word_matrix[i])\n",
    "\n",
    "    # remove query word\n",
    "    similarity_scores[query_id] = 0\n",
    "    filter_word2idx = dict([(k, v) for k, v in word2idx.items() if k != query])\n",
    "    filter_idx2word = dict([(k, v) for k, v in idx2word.items() if k != query_id])\n",
    "    \n",
    "    # sorting by similarity score\n",
    "    top_k_idx = (-similarity_scores).argsort()[:top_k]\n",
    "    top_k_word = [filter_idx2word[word_idx] for word_idx in top_k_idx]\n",
    "    \n",
    "    return dict(zip(top_k_word, similarity_scores[top_k_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query] : you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.8660253941251804, 'i': 0.7071067726510136, '.': 0.49999999292893216}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_similarity('you', word2idx, idx2word, co_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正向點間互資訊(PPMI)\n",
    "由於共生矩陣在高頻字上的缺陷，而PMI中加入了兩字詞共同出現的機率與各自出現的機率的關係，以此解決高頻詞在共生矩陣上的缺陷。\n",
    "而PPMI即將PMI內會產生負值的情況排除(若出現負值則賦予0)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&PMI(x,y) = log_2\\frac{P(x,y)}{P(x)P(y)} = log_2\\frac{C(x,y)N}{C(x)C(y)} \\\\\n",
    "&PPMI(x,y) = max(0,PMI(x,y))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義正向點間互資訊\n",
    "\n",
    "def ppmi(co_matrix: np.ndarray, eps: float=1e-8, verbose: bool=False):\n",
    "    M = np.zeros_like(co_matrix, dtype=np.float32)\n",
    "    N = np.sum(co_matrix)\n",
    "    S = np.sum(co_matrix, axis=0)\n",
    "    total = co_matrix.shape[0]*co_matrix.shape[1]\n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(co_matrix.shape[0]):\n",
    "        for j in range(co_matrix.shape[1]):\n",
    "            pmi = np.log2(co_matrix[i, j]*N / (S[i]*S[j] + eps))\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % 10 == 0 or cnt == total:\n",
    "                    print(f\"{cnt}/{total} Done\")\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/49 Done\n",
      "20/49 Done\n",
      "30/49 Done\n",
      "40/49 Done\n",
      "49/49 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log2\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.8930848, 0.       , 0.       , 0.       , 1.7004397,\n",
       "        0.       ],\n",
       "       [0.8930848, 0.       , 0.8930848, 0.3081223, 0.       , 0.       ,\n",
       "        0.8930848],\n",
       "       [0.       , 0.8930848, 0.       , 2.1154773, 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.3081223, 2.1154773, 0.       , 1.1154772, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , 1.1154772, 0.       , 0.7004397,\n",
       "        0.7004397],\n",
       "       [1.7004397, 0.       , 0.       , 0.       , 0.7004397, 0.       ,\n",
       "        0.7004397],\n",
       "       [0.       , 0.8930848, 0.       , 0.       , 0.7004397, 0.7004397,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ppmi = ppmi(co_matrix, verbose=True)\n",
    "output_ppmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "觀察上面的PPMI輸出矩陣，可以發現大部分的元素都為0(稀疏矩陣)，因此可以發現此矩陣包含了許多無法提供訊息的元素，利用奇異值分解，將矩陣降維，並保存重要的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in co-occurrence matrix: [0 1 1 0 1 0 0]\n",
      "hello in PPMI: [0.        0.3081223 2.1154773 0.        1.1154772 0.        0.       ]\n",
      "hello in SVD: [-0.5126197   0.5698161   0.39725903 -0.4323913  -0.01054526 -0.124419\n",
      " -0.22839099]\n"
     ]
    }
   ],
   "source": [
    "# 使用np的linalg.svd對PPMI矩陣進行奇異值分解\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(output_ppmi)\n",
    "\n",
    "# 使用SVD將將原本的稀疏向量轉變為稠密向量\n",
    "print(f\"hello in co-occurrence matrix: {co_matrix[word2idx['hello']]}\")\n",
    "print(f\"hello in PPMI: {output_ppmi[word2idx['hello']]}\")\n",
    "print(f\"hello in SVD: {U[word2idx['hello']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.92635028e-08  8.93084764e-01 -7.11651316e-09 -4.49460344e-08\n",
      "   1.34603795e-08  1.70043969e+00  1.45025325e-09]\n",
      " [ 8.93084764e-01  2.52935042e-08  8.93084824e-01  3.08122218e-01\n",
      "  -2.37586200e-08  4.47104114e-08  8.93084824e-01]\n",
      " [-6.68377638e-08  8.93084824e-01 -1.76178805e-08  2.11547732e+00\n",
      "   1.77927717e-08 -5.17287262e-08 -5.30116395e-08]\n",
      " [-4.88651040e-08  3.08122247e-01  2.11547732e+00 -3.03451451e-08\n",
      "   1.11547709e+00  1.45353560e-08 -5.35544444e-08]\n",
      " [ 1.35580214e-08  1.72256680e-08  1.78285688e-08  1.11547709e+00\n",
      "   1.23703447e-08  7.00439751e-01  7.00439632e-01]\n",
      " [ 1.70043981e+00  1.91322336e-09 -3.84810370e-08 -4.64926551e-08\n",
      "   7.00439751e-01  6.17670821e-08  7.00439692e-01]\n",
      " [-4.47034836e-08  8.93084884e-01 -5.40167093e-08 -4.84287739e-08\n",
      "   7.00439632e-01  7.00439632e-01 -1.49011612e-08]]\n",
      "[[0.        0.8930848 0.        0.        0.        1.7004397 0.       ]\n",
      " [0.8930848 0.        0.8930848 0.3081223 0.        0.        0.8930848]\n",
      " [0.        0.8930848 0.        2.1154773 0.        0.        0.       ]\n",
      " [0.        0.3081223 2.1154773 0.        1.1154772 0.        0.       ]\n",
      " [0.        0.        0.        1.1154772 0.        0.7004397 0.7004397]\n",
      " [1.7004397 0.        0.        0.        0.7004397 0.        0.7004397]\n",
      " [0.        0.8930848 0.        0.        0.7004397 0.7004397 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 檢查分解是否正確\n",
    "A = U @ np.diag(S) @ V\n",
    "print(A)\n",
    "print(output_ppmi)\n",
    "# 可以發先做完SVD得結果跟原來的output_ppmi是相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9371588  2.5547988  2.1101685  1.9556583  1.1257027  0.58972406\n",
      " 0.30812874]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.29432744, -0.29746115,  0.5294562 ,  0.511355  ,  0.22169203,\n",
       "         0.35262936],\n",
       "       [-0.3710324 ,  0.26495245, -0.31999645,  0.0807369 ,  0.45295563,\n",
       "         0.4691856 ],\n",
       "       [-0.48203   , -0.56445074, -0.26282662, -0.430857  , -0.33953863,\n",
       "         0.2642201 ],\n",
       "       [-0.5126197 ,  0.5698161 ,  0.39725903, -0.4323913 , -0.01054526,\n",
       "        -0.124419  ],\n",
       "       [-0.33312967, -0.30777904, -0.16466641,  0.03673923,  0.5294517 ,\n",
       "        -0.6964652 ],\n",
       "       [-0.31352073,  0.30776063, -0.48896635,  0.5457005 , -0.38465765,\n",
       "        -0.12412582],\n",
       "       [-0.26702777, -0.09261478,  0.3523957 ,  0.24547683, -0.44945022,\n",
       "        -0.26410997]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以發現前六個奇異值就佔了絕大多數的奇異值\n",
    "print(S)\n",
    "\n",
    "# 可以取前六個維度當作降為的詞向量\n",
    "U_reduce = U[:, 0:6]\n",
    "U_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 將詞向量降為二維方便視覺化\n",
    "U_visualization = U[:, 0:2]\n",
    "\n",
    "# visualization\n",
    "for word, word_id in word2idx.items():\n",
    "    plt.annotate(word, (U_reduce[word_id, 0], U_reduce[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U_reduce[:, 0], U_reduce[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
